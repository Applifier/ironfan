= DESCRIPTION:

Installs Apache hadoop and sets up a basic distributed cluster per the quick start documentation.

= REQUIREMENTS:

== Platform:

Tested on Ubuntu 8.10, though should work on most Linux distributions, see hadoop[:java_home].

== Cookbooks:

Opscode cookbooks, http://github.com/opscode/cookbooks/tree/master:

* java

= ATTRIBUTES: 

* hadoop[:version]     - Specify the version of hadoop to install. Default 0.20
* hadoop[:cdh_version] - Specify the cloudera distribution version. Default is cdh3 -- see http://archive.cloudera.com/docs/_apt.html

You may wish to add more attributes for tuning the configuration file templates.

= USAGE:

This cookbook installs hadoop from the cloudera CDH3 distribution[1] . You should copy this to a site-cookbook and modify the templates to meet your requirements. 

Once the recipe is run, the distributed filesystem can be formated using the script /usr/bin/hadoop. 

  sudo -u hadoop /usr/bin/hadoop namenode -format
  
You may need to set up SSH keys for hadoop management commands. 

The various hadoop processes are installed as services. Do NOT use the start-all.sh scripts.  

The recipes correspond to different roles you'll probably assign: 
* pseudo-conf       -- single machine pseudo-distributed mode
* jobtracker        -- assigns and coordinates jobs
* namenode          -- runs the namenode (coordinates the HDFS) and secondarynamenode (backs up the metadata file)
* worker            -- runs the datanode and tasktracker
* secondarynamenode -- additional secondarynamenode (backs up the metadata file).

Assign node roles according to these rough guidelines:

* For initial testing, use pseudo-conf mode.
* For clusters of some to a dozen or so nodes, give the master node the jobtracker, namenode *and* worker roles.
* For larger clusters, omit the worker role for the master node.
* For huge clusters, run the jobtracker and namenode/secondarynamenode on different hosts.

Note that the secondarynamenode is NOT a redundant namenode. All it does is make periodic backups of the HDFS metadata.

[1] http://archive.cloudera.com/docs/

= LICENSE and AUTHOR:
      
Author:: Joshua Timberman (<joshua@opscode.com>), Flip Kromer (<flip@infochimps.org>), much code taken from Tom White (<tom@cloudera.com>)'s hadoop-ec2 scripts

Copyright:: 2009, Opscode, Inc

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
